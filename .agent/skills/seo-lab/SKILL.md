---
name: Antigravity Engineering Protocol
description: The comprehensive engineering guidebook. MANDATORY for all coding tasks. Includes rules for Strict TypeScript, Testing, Multi-Agent Coordination, and Artifact generation. Load this skill at the start of every session.
---

# ğŸ§  Antigravity Engineering Protocol (SKILL.md)	
> Version: 1.1 | Role: Senior AI Full-stack Engineer	
> **Enhanced Edition** with Production-Ready Guidelines	
	
This document defines the high-level execution strategy for AI Agents in this project. Follow these rules strictly to ensure high-quality, bug-free, and token-efficient development.	
	
---	
	
## ğŸ—ï¸ 1. Context & Architecture Management	
	
### Core Documentation	
- **Source of Truth:** Before starting any task, always reference `PRD.md` and `architecture.md`.	
- **Feature Tracking:** Maintain and update `feature.json` after every significant task completion to track progress and state.	
- **Real-time Docs:** Use the integrated **MCP Context 7** or Browser tool to fetch the latest documentation for libraries before implementation. Do not rely on stale training data.	
	
### ğŸ†• Enhanced Context Management	
- **Session Markers:** Add timestamps and session IDs to `feature.json` updates for better tracking:	
```json	
{	
feature_id: "AUTH-001",	
status: "in_progress",	
last_updated: "2024-02-14T10:30:00Z",	
session_id: "session_abc123",	
blocked_by: null	
}	
```	
- **Dependency Mapping:** Document feature dependencies in `feature.json` to prevent circular dependencies	
- **Context Snapshots:** Create context snapshots every 3-5 major changes in `/docs/snapshots/` with naming format: `context_YYYY-MM-DD_HHmm.md`	
	
---	
	
## ğŸ›¡ï¸ 2. Development Guardrails	
	
### Type Safety	
- **Strict Mode:** Always enforce `strict: true` in `tsconfig.json`. If types are missing, create them; do not use `any`.	
- **ğŸ†• Type Validation:** Before committing, run `tsc --noEmit` to catch type errors early	
- **ğŸ†• No Implicit Any:** Set `noImplicitAny: true` and `strictNullChecks: true`	
	
### Protected Files	
- **DO NOT modify** files in `.github/`, `tests/`, or `config/` unless explicitly instructed. If a test fails, fix the logic, not the test.	
- **Hook Compliance:** Respect all pre-commit and pre-push hooks. If a command returns `exit code 2`, stop and re-evaluate the strategy.	
	
### ğŸ†• Code Integrity Rules	
- **Never Delete Tests:** If a test fails, it's exposing a real issue. Fix the implementation, not the assertion.	
- **Configuration Changes:** Any changes to `package.json`, `tsconfig.json`, or environment configs must be logged in `CHANGELOG.md` with rationale	
- **Migration Scripts:** For database or breaking changes, always create a rollback script alongside the migration	
- **ğŸ†• Backup Critical Files:** Before making risky changes, create a backup: `cp file.ts file.ts.backup.YYYYMMDD`	
	
---	
	
## ğŸš€ 3. Execution Strategy (Agent-First Workflow)	
	
### Parallelization	
- **Parallel Worktrees:** When handling multiple unrelated features, suggest creating a new **Git Worktree** to avoid workspace pollution and conflicts.	
```bash	
git worktree add ../feature-auth feature/auth	
git worktree add ../feature-payments feature/payments	
```	
- **Mission Control:** Use the **Manager View** to coordinate sub-agents for frontend and backend tasks simultaneously.	
	
### ğŸ†• Work Distribution Strategy	
- **Feature Isolation:** Each major feature should have its own worktree or branch	
- **Small Commits:** Commit after each logical unit of work (max 200-300 lines changed)	
- **Branch Naming Convention:**	
- `feature/[feature-name]` - New features	
- `fix/[bug-description]` - Bug fixes	
- `refactor/[component]` - Code refactoring	
- `docs/[section]` - Documentation updates	
### ğŸ†• Multi-Agent Coordination (Manager View)	
- **Role Definition:** The primary Agent acts as the **Coordinator (Manager)**. You are responsible for high-level planning and delegating tasks to specialized Sub-Agents (e.g., Frontend Specialist, Backend Specialist).	
- **Delegation Protocol:** Before delegating, create a "Task Brief" in the Manager View containing:	
1. Success Criteria	
2. Dependencies from `feature.json`	
3. Reference to specific sections in `SKILL.md`	
- **Sub-Agent Oversight:** The Manager must review the code generated by Sub-Agents using the **Adversarial Review** process (Section 4) before merging into the main worktree.	
- **Conflict Resolution:** If two Sub-Agents propose conflicting changes, the Manager must use the **Decision Framework (Section 6)** to resolve and document the final choice.	
- **Every major change** must be accompanied by an Artifact (Summary of changes + Verification logs).	
	
### ğŸ†• Enhanced Artifact Requirements	
- **Change Summary Format:**	
```markdown	
## Changes Made	
- **Files Modified:** [list]	
- **New Dependencies:** [list]	
- **Breaking Changes:** [yes/no + description]	
- **Migration Required:** [yes/no]	
- **Performance Impact:** [low/medium/high]	
	
### ğŸ†• Antigravity-Specific Artifacts (Interactive Preview)	
- **Separate Artifact Files:** For every UI component or complex logic, generate a dedicated artifact file in `.antigravity/artifacts/` with the naming format `[feature-id]-[description].md`.	
- **Live Preview Requirement:** When creating UI components, include a simplified HTML/TSX preview block in the artifact file to trigger Antigravity's **Live Preview** window.Always include a screenshot or DOM recording link in the Artifact.	
- **Verification Logs:** Attach terminal output or test results directly into the artifact file to provide "Evidence of Work" for the Manager View.	
	
## Verification	
- âœ… TypeScript compilation passed	
- âœ… All tests passing (X/X)	
- âœ… Linter checks passed	
- âœ… Manual testing completed	
```	
	
---	
	
## ğŸ§ª 4. Quality Control & Testing	
	
### Testing Strategy	
- **User Story Driven:** Do not just write Unit Tests. Generate **User Stories** and use the **Integrated Browser** to perform E2E testing.	
- **Adversarial Review:** Before declaring a task "Done", perform a self-critique. If multiple agents are active, initiate a **Critic Agent** pass to find vulnerabilities.	
- **Pre-Mortem Analysis:** Use the **Reverse Prompting** technique. Ask: "How could this implementation fail in production?" and address those points proactively.	
	
### ğŸ†• Comprehensive Testing Checklist	
	
#### Unit Tests	
- [ ] All pure functions have tests	
- [ ] Edge cases covered (null, undefined, empty arrays, etc.)	
- [ ] Error handling paths tested	
- [ ] Mock external dependencies	
	
#### Integration Tests	
- [ ] API endpoints tested with real database	
- [ ] Authentication/Authorization flows verified	
- [ ] Third-party service integrations mocked/tested	
	
#### E2E Tests (User Stories)	
- [ ] Happy path: User can complete core workflow	
- [ ] Error path: User sees appropriate error messages	
- [ ] Edge cases: Boundary conditions handled gracefully	
- [ ] Accessibility: Keyboard navigation works	
- [ ] Performance: Key pages load < 3s	
	
#### ğŸ†• Testing Anti-Patterns (Avoid These)	
- âŒ Testing implementation details instead of behavior	
- âŒ Tests that depend on execution order	
- âŒ Hardcoded timestamps or IDs in assertions	
- âŒ Tests that pass locally but fail in CI	
- âŒ Flaky tests (fix or delete them)	
	
### ğŸ†• Pre-Deployment Checklist	
- [ ] All tests passing in CI/CD	
- [ ] No console errors in browser	
- [ ] No TypeScript errors (`tsc --noEmit`)	
- [ ] No linter warnings (`eslint --max-warnings 0`)	
- [ ] Performance budget not exceeded	
- [ ] Security scan completed (npm audit, Snyk)	
- [ ] Accessibility score > 90 (Lighthouse)	
- [ ] Database migrations tested on staging	
- [ ] Rollback plan documented	
	
---	
	
## ğŸ§¹ 5. Optimization & Token Efficiency	
	
### Context Management	
- **MCP CLI Mode:** Prefer `mcp_cli_mode: true` for on-demand tool usage to keep the context window clean.	
- **Compact Sessions:** If the session history becomes too long, summarize the current state into `feature.json` and start a fresh context to avoid "Hallucinations".	
	
### ğŸ†• Advanced Token Optimization	
- **Lazy Loading Docs:** Don't load all MCP servers at once. Load only what's needed for current task	
- **Incremental File Editing:** For large files, use `str_replace` on specific sections instead of rewriting entire files	
- **Diff-Based Communication:** When reviewing code, focus on diffs rather than full file contents	
- **Summary Checkpoints:** Every 10-15 tool calls, create a brief summary checkpoint to maintain context clarity	
	
### ğŸ†• Session Management	
```bash	
# At start of new session	
1. Load feature.json to understand current state	
2. Check for any blockers or pending reviews	
3. Load only relevant documentation for current task	
4. Set clear success criteria before starting	
	
# During long sessions (every 30 minutes)	
1. Update feature.json with progress	
2. Commit working code (even if incomplete)	
3. Clear unnecessary context	
4. Re-assess remaining work	
	
# At end of session	
1. Commit all changes	
2. Update feature.json with final status	
3. Document any blockers or next steps	
4. Run `analyze session` for insights	
```	
	
---	
	
## ğŸ› ï¸ Performance Commands for Agent	
	
### Core Commands	
- `analyze session`: Run at the end of the day to generate insights for the next session.	
- `verify UI`: Use **Vercel Agent Browser** or Accessibility Tree to verify UI changes instead of heavy screenshots.	
	
### ğŸ†• Extended Command Library	
	
#### Debugging Commands	
```bash	
# Quick health check	
npm run typecheck && npm run lint && npm test	
	
# Dependency audit	
npm audit --production	
npm outdated	
	
# Bundle analysis	
npm run build -- --analyze	
	
# Performance profiling	
npm run build -- --profile	
```	
	
#### Context Commands	
```bash	
# View current feature status	
cat feature.json | jq '.features[] | select(.status=="in_progress")'	
	
# Check for stale branches	
git branch --merged main | grep -v main	
	
# Find TODO comments	
grep -r "TODO" src/ --exclude-dir=node_modules	
```	
	
#### Recovery Commands	
```bash	
# Reset to last known good state	
git reset --hard HEAD~1	
	
# Stash and clean workspace	
git stash && git clean -fd	
	
# Restore from backup	
cp file.ts.backup.20240214 file.ts	
```	
	
---	
	
## ğŸ¯ 6. Decision Framework (NEW SECTION)	
	
When faced with ambiguous requirements or technical decisions, use this framework:	
	
### Step 1: Clarify Requirements	
- â“ What is the user trying to accomplish?	
- â“ What are the acceptance criteria?	
- â“ What are the constraints (time, budget, tech stack)?	
	
### Step 2: Evaluate Options	
- List 2-3 viable approaches	
- For each, note:	
- âœ… Pros: Benefits, alignment with architecture	
- âŒ Cons: Risks, technical debt, complexity	
- â±ï¸ Estimated effort	
- ğŸ”® Future maintainability	
	
### Step 3: Document Decision	
- Record in `docs/decisions/ADR-XXX-[topic].md` using Architecture Decision Record format	
- Include: Context, Decision, Consequences, Alternatives Considered	
	
### Step 4: Validate Assumption	
- Before implementing, ask: "What could make this decision wrong?"	
- Check with stakeholders if decision affects user experience or API contracts	
	
---	
	
## ğŸš¨ 7. Error Recovery Patterns (NEW SECTION)	
	
### When Tests Fail	
1. âŒ **Don't:** Modify the test to make it pass	
2. âœ… **Do:** Understand what behavior changed and why	
3. âœ… **Do:** Fix the implementation to match expected behavior	
4. âœ… **Do:** If behavior change is intentional, update test AND document in CHANGELOG	
	
### When Build Fails	
1. Read the full error message (don't skim)	
2. Check if it's a dependency issue: `rm -rf node_modules && npm install`	
3. Check if it's a type issue: Review recent type changes	
4. Check if it's a configuration issue: Compare with last working commit	
	
### When Context Window is Full	
1. Save current progress to `feature.json`	
2. Commit working code with descriptive message	
3. Create summary document: `/docs/session-summaries/YYYY-MM-DD.md`	
4. Start fresh context with clear objective	
	
### When Stuck in a Loop	
1. **Stop:** Don't make more than 3 attempts at the same approach	
2. **Reflect:** What assumption might be wrong?	
3. **Pivot:** Try a completely different approach	
4. **Ask:** Document the problem and ask for human review	
	
---	
	
## ğŸ“Š 8. Metrics & Success Criteria (NEW SECTION)	
	
### Code Quality Metrics	
- **Type Coverage:** > 95% (no `any` types)	
- **Test Coverage:** > 80% lines, > 90% branches	
- **Linter Warnings:** 0 (enforce with `--max-warnings 0`)	
- **Cyclomatic Complexity:** < 10 per function	
- **Bundle Size:** Track and alert on 10%+ increases	
	
### Performance Metrics	
- **First Contentful Paint:** < 1.5s	
- **Time to Interactive:** < 3.5s	
- **Lighthouse Score:** > 90 (Performance, Accessibility, Best Practices)	
- **Core Web Vitals:** All metrics in "Good" range	
	
### Development Efficiency Metrics	
- **Build Time:** < 2 minutes	
- **Test Suite Time:** < 5 minutes	
- **Hot Reload Time:** < 2 seconds	
- **Token Usage per Feature:** Track and optimize	
	
---	
	
## ğŸ“ 9. Learning & Continuous Improvement (NEW SECTION)	
	
### Post-Incident Reviews	
After any bug reaches production or causes significant delay:	
1. Document what happened in `/docs/postmortems/`	
2. Identify root cause (not just symptoms)	
3. List preventive measures	
4. Update this SKILL.md with lessons learned	
	
### Session Retrospectives	
Weekly review:	
- What went well? (Reinforce these practices)	
- What could be better? (Add to this document)	
- What slowed us down? (Create automation)	
- What surprised us? (Update architecture docs)	
	
### Knowledge Capture	
- Document non-obvious solutions in `/docs/recipes/`	
- Create runbooks for common tasks in `/docs/runbooks/`	
- Maintain FAQ in `/docs/FAQ.md`	
	
---	
	
## ğŸ”— 10. Integration & Handoff (NEW SECTION)	
	
### When Handing Off to Another Agent	
Provide:	
1. Current state summary from `feature.json`	
2. What was completed in this session	
3. What's blocked and why	
4. Next logical steps	
5. Any gotchas or warnings	
	
### When Receiving Handoff	
Verify:	
1. All tests are passing	
2. Code compiles without errors	
3. No uncommitted changes unless documented	
4. Review recent commits for context	
5. Check for any TODOs or FIXMEs added	
	
### When Integrating External Changes	
1. Review changes carefully (don't auto-merge)	
2. Run full test suite after merge	
3. Check for breaking changes in dependencies	
4. Update docs if APIs changed	
5. Verify in local environment before deploying	
	
---	
	
## ğŸ¯ Quick Reference Card	
	
### Before Starting Any Task	
- [ ] Read PRD.md and architecture.md	
- [ ] Check feature.json for current state	
- [ ] Load relevant MCP docs	
- [ ] Set clear success criteria	
- [ ] Estimate token budget	
	
### During Implementation	
- [ ] Follow strict TypeScript mode	
- [ ] Write tests alongside code	
- [ ] Commit frequently (every logical unit)	
- [ ] Update feature.json on progress	
- [ ] Don't modify protected files	
	
### Before Marking Done	
- [ ] All tests passing	
- [ ] No TypeScript errors	
- [ ] No linter warnings	
- [ ] Run pre-mortem analysis	
- [ ] Update artifacts and docs	
- [ ] Commit and push changes	
	
### Emergency Procedures	
- **Context Full:** Save state â†’ Commit â†’ Summarize â†’ Fresh start	
- **Tests Failing:** Fix logic, not tests	
- **Stuck in Loop:** Stop after 3 attempts â†’ Pivot approach	
- **Build Broken:** Check dependencies â†’ Check types â†’ Check config	
	
---	
	
## ğŸ“š Additional Resources	
	
### Internal Documentation	
- `/docs/PRD.md` - Product Requirements	
- `/docs/architecture.md` - System Architecture	
- `/docs/decisions/` - Architecture Decision Records	
- `/docs/runbooks/` - Operational Procedures	
- `/docs/recipes/` - Common Solutions	
	
### External References	
- **TypeScript Handbook:** https://www.typescriptlang.org/docs/	
- **Testing Best Practices:** https://testingjavascript.com/	
- **Git Worktrees Guide:** https://git-scm.com/docs/git-worktree	
- **MCP Documentation:** https://modelcontextprotocol.io/	
	
---	
	
## ğŸ”„ Version History	
	
### v1.1 (Current)	
- âœ¨ Added Decision Framework section	
- âœ¨ Added Error Recovery Patterns	
- âœ¨ Added Metrics & Success Criteria	
- âœ¨ Added Learning & Continuous Improvement	
- âœ¨ Added Integration & Handoff guidelines	
- âœ¨ Enhanced existing sections with practical examples	
- âœ¨ Added Quick Reference Card	
	
### v1.0	
- Initial version with core guidelines	
	
---	
	
**Remember:** This is a living document. Update it when you discover better practices or encounter new edge cases. The goal is to make every session more efficient than the last. ğŸš€	
	